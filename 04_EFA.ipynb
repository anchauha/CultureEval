{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4804818",
   "metadata": {},
   "source": [
    "# WVS Wave 7 Data Analysis - EFA Model Comparison\n",
    "\n",
    "This script compares different Exploratory Factor Analysis (EFA) models by iterating through various extraction methods and rotation types for a specified number of factors. It calculates metrics like explained variance, RMSR, simple structure count, factor correlations, and model fit indices (for ML) to help identify the best-fitting model configuration based on the aggregated data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c664c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Imports\n",
    "# =============================================================================\n",
    "from __future__ import annotations\n",
    "import argparse\n",
    "import datetime as dt\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity, calculate_kmo\n",
    "# NOTE: Imputation imports removed - assuming aggregated data is complete.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c5fffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Configuration / Constants\n",
    "# =============================================================================\n",
    "DATA_DIR = pathlib.Path(\"./data\")\n",
    "OUTPUT_DIR_ROOT = pathlib.Path(\"./output/efa_comparison\")\n",
    "\n",
    "# --- Input Data ---\n",
    "# AGGREGATED_DATA_PATH = DATA_DIR / \"wvs_wave7_aggregated_by_demographics.csv\"\n",
    "AGGREGATED_DATA_PATH = DATA_DIR / \"new_median_wvs_wave7_aggregated_by_demographics.csv\"\n",
    "# File containing variable codes (needed to identify survey columns)\n",
    "VARIABLE_INFO_PATH = DATA_DIR / \"variable_info.csv\" # Ensure this matches previous scripts\n",
    "\n",
    "# --- EFA Comparison Parameters ---\n",
    "RANDOM_STATE = 42\n",
    "DEFAULT_N_FACTORS = 5 # Example: Number of factors to compare models for\n",
    "DEFAULT_LOADING_THRESHOLD = 0.40 # For simple structure calculation\n",
    "METHODS_TO_COMPARE = [\"minres\", \"principal\", \"ml\"] # EFA extraction methods\n",
    "ROTATIONS_TO_COMPARE = [\"promax\", \"oblimin\", \"varimax\"] # Rotation types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e5390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Helper Functions\n",
    "# =============================================================================\n",
    "\n",
    "def ensure_output_dir(root: pathlib.Path, prefix: str = \"\") -> pathlib.Path:\n",
    "    \"\"\"Creates a date-stamped output directory.\"\"\"\n",
    "    today = dt.date.today().isoformat().replace(\"-\", \"\")\n",
    "    dir_name = f\"{prefix}{today}\" if prefix else today\n",
    "    out_path = root / dir_name\n",
    "    out_path.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Output directory created/ensured: {out_path}\")\n",
    "    return out_path\n",
    "\n",
    "def log_message(msg: str) -> None:\n",
    "    \"\"\"Prints a message to the console.\"\"\"\n",
    "    print(msg, flush=True)\n",
    "\n",
    "def calculate_rmsr(observed_corr: np.ndarray, reproduced_corr: np.ndarray) -> float:\n",
    "    \"\"\"Root Mean Square Residual of off-diagonal elements.\"\"\"\n",
    "    if observed_corr.shape != reproduced_corr.shape:\n",
    "        raise ValueError(\"Observed and reproduced correlation matrices must have the same shape.\")\n",
    "    residual = observed_corr - reproduced_corr\n",
    "    # Get lower triangle indices (excluding diagonal k=-1)\n",
    "    lower_triangle_indices = np.tril_indices_from(residual, k=-1)\n",
    "    squared_residuals = residual[lower_triangle_indices] ** 2\n",
    "    rmsr_value = np.sqrt(np.mean(squared_residuals))\n",
    "    return float(rmsr_value)\n",
    "\n",
    "def count_simple_structure(loadings: pd.DataFrame, threshold: float) -> int:\n",
    "    \"\"\"Counts variables loading significantly onto exactly one factor.\"\"\"\n",
    "    if threshold <= 0:\n",
    "        return 0 # Threshold must be positive\n",
    "\n",
    "    # Create a boolean mask where absolute loading >= threshold\n",
    "    significant_mask = loadings.abs() >= threshold\n",
    "\n",
    "    # Count how many factors each variable loads significantly onto\n",
    "    loadings_per_variable = significant_mask.sum(axis=1)\n",
    "\n",
    "    # Count how many variables load onto exactly one factor\n",
    "    simple_structure_count = int((loadings_per_variable == 1).sum())\n",
    "    return simple_structure_count\n",
    "\n",
    "def load_data_for_comparison(aggregated_path: pathlib.Path, variable_info_path: pathlib.Path) -> pd.DataFrame:\n",
    "    \"\"\"Loads aggregated data and identifies survey columns for EFA.\"\"\"\n",
    "    log_message(\"--- Loading Data for Comparison ---\")\n",
    "    # Load aggregated data\n",
    "    if not aggregated_path.exists():\n",
    "        raise FileNotFoundError(f\"Aggregated data file not found: {aggregated_path}\")\n",
    "    try:\n",
    "        df_agg = pd.read_csv(aggregated_path)\n",
    "        log_message(f\"Loaded aggregated data: {df_agg.shape}\")\n",
    "    except Exception as e:\n",
    "        raise IOError(f\"Error reading aggregated data file '{aggregated_path}': {e}\")\n",
    "\n",
    "    # Identify survey columns using variable info file\n",
    "    survey_cols = []\n",
    "    if variable_info_path.exists():\n",
    "        try:\n",
    "            var_info_df = pd.read_csv(variable_info_path)\n",
    "            known_vars = var_info_df['Variable_Code'].tolist()\n",
    "            survey_cols = [col for col in df_agg.columns if col in known_vars]\n",
    "            log_message(f\"Identified {len(survey_cols)} survey columns based on variable info file.\")\n",
    "        except Exception as e:\n",
    "            log_message(f\"Warning: Could not load/process variable info file '{variable_info_path}': {e}\")\n",
    "    else:\n",
    "        log_message(f\"Warning: Variable info file not found at '{variable_info_path}'.\")\n",
    "\n",
    "    # Fallback if survey_cols identification failed\n",
    "    if not survey_cols:\n",
    "        survey_cols = df_agg.select_dtypes(include=np.number).columns.tolist()\n",
    "        # Exclude potential demographic columns if they are numeric by chance\n",
    "        demo_cols_in_data = [col for col in AGGREGATION_DEMOGRAPHIC_VARS if col in survey_cols]\n",
    "        if demo_cols_in_data:\n",
    "             survey_cols = [col for col in survey_cols if col not in demo_cols_in_data]\n",
    "        log_message(f\"Warning: Identifying survey columns via fallback (numeric type). Found {len(survey_cols)} columns.\")\n",
    "\n",
    "\n",
    "    if not survey_cols:\n",
    "         raise ValueError(\"Could not identify survey question columns for EFA.\")\n",
    "\n",
    "    df_efa_input = df_agg[survey_cols]\n",
    "\n",
    "    # Check for NaNs\n",
    "    if df_efa_input.isnull().any().any():\n",
    "        log_message(\"Warning: Missing values found in data for EFA comparison. This might indicate issues in prior steps.\")\n",
    "\n",
    "    return df_efa_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ca5126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Core Comparison Function\n",
    "# =============================================================================\n",
    "\n",
    "def compare_efa_models(\n",
    "    df_efa_input: pd.DataFrame,\n",
    "    n_factors: int,\n",
    "    methods: list[str],\n",
    "    rotations: list[str],\n",
    "    simple_structure_threshold: float\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Iterates through EFA models and compiles comparison metrics.\"\"\"\n",
    "    log_message(f\"\\n--- Comparing EFA Models (n_factors={n_factors}) ---\")\n",
    "\n",
    "    # --- Suitability Check ---\n",
    "    try:\n",
    "        chi_square_value, p_value = calculate_bartlett_sphericity(df_efa_input)\n",
    "        kmo_per_variable, kmo_overall = calculate_kmo(df_efa_input)\n",
    "        log_message(f\"Data Suitability: Bartlett p={p_value:.4g}, Overall KMO={kmo_overall:.3f}\")\n",
    "        if p_value > 0.05 or kmo_overall < 0.6:\n",
    "             log_message(\"Warning: Data suitability for EFA may be questionable based on tests.\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Warning: Could not perform suitability tests: {e}\")\n",
    "\n",
    "    # --- Iterate through Model Combinations ---\n",
    "    observed_corr_matrix = df_efa_input.corr().values # Calculate once\n",
    "    summary_data = []\n",
    "\n",
    "    for method in methods:\n",
    "        for rotation in rotations:\n",
    "            log_message(f\"Fitting Model: Method='{method}', Rotation='{rotation}'\")\n",
    "            try:\n",
    "                fa = FactorAnalyzer(\n",
    "                    n_factors=n_factors,\n",
    "                    method=method,\n",
    "                    rotation=rotation,\n",
    "                    use_smc=True, # Use squared multiple correlation\n",
    "                    rotation_kwargs={\"max_iter\": 1000} # For promax/oblimin\n",
    "                )\n",
    "                fa.fit(df_efa_input)\n",
    "\n",
    "                # --- Calculate Metrics ---\n",
    "                # Variance Explained\n",
    "                _, prop_var, cum_var = fa.get_factor_variance()\n",
    "                total_explained_pct = cum_var[-1] * 100 if cum_var.size > 0 else 0.0\n",
    "\n",
    "                # RMSR (Root Mean Square Residual)\n",
    "                loadings = fa.loadings_\n",
    "                if hasattr(fa, 'communalities_'):\n",
    "                     communalities = fa.communalities_ # Newer versions\n",
    "                else:\n",
    "                     communalities = (loadings**2).sum(axis=1) # Older versions\n",
    "                \n",
    "                # Ensure communalities have the right shape/index if needed\n",
    "                reproduced_corr = loadings @ loadings.T + np.diag(communalities) # Corrected formula for reproduced correlation\n",
    "                rmsr = calculate_rmsr(observed_corr_matrix, reproduced_corr)\n",
    "\n",
    "\n",
    "                # Simple Structure Count\n",
    "                loadings_df = pd.DataFrame(loadings, index=df_efa_input.columns)\n",
    "                simple_structure_count = count_simple_structure(loadings_df, simple_structure_threshold)\n",
    "\n",
    "                # Max Factor Correlation (Phi) for oblique rotations\n",
    "                max_abs_phi = 0.0\n",
    "                if fa.phi_ is not None:\n",
    "                    phi_lower_triangle = np.abs(np.tril(fa.phi_, k=-1))\n",
    "                    if phi_lower_triangle.size > 0:\n",
    "                         max_abs_phi = float(phi_lower_triangle.max())\n",
    "\n",
    "                # ML-specific Fit Indices (ChiSq/df, RMSEA)\n",
    "                chi_sq_per_df = np.nan\n",
    "                rmsea = np.nan\n",
    "                if method == \"ml\":\n",
    "                    try:\n",
    "                        model_stats = fa.get_model_stats()\n",
    "                        if model_stats and model_stats.get(\"dof\", 0) > 0:\n",
    "                             chi_sq_per_df = model_stats[\"chi_square\"] / model_stats[\"dof\"]\n",
    "                             rmsea = model_stats.get(\"rmsea\", np.nan)\n",
    "                    except Exception as ml_stat_error:\n",
    "                        log_message(f\"  Warning: Could not get ML stats for {method}+{rotation}: {ml_stat_error}\")\n",
    "\n",
    "                # Append results\n",
    "                summary_data.append({\n",
    "                    \"Method\": method,\n",
    "                    \"Rotation\": rotation,\n",
    "                    \"Explained_Var(%)\": total_explained_pct,\n",
    "                    \"RMSR\": rmsr,\n",
    "                    \"ChiSq_per_DF\": chi_sq_per_df, # Only for ML\n",
    "                    \"RMSEA\": rmsea, # Only for ML\n",
    "                    \"Simple_Structure_Count\": simple_structure_count,\n",
    "                    \"Max_Abs_Factor_Corr\": max_abs_phi, # Only for oblique\n",
    "                })\n",
    "\n",
    "            except Exception as fit_error:\n",
    "                warnings.warn(f\"Model fitting failed for Method='{method}', Rotation='{rotation}': {fit_error}\")\n",
    "                summary_data.append({\n",
    "                    \"Method\": method, \"Rotation\": rotation, \"Explained_Var(%)\": np.nan,\n",
    "                    \"RMSR\": np.nan, \"ChiSq_per_DF\": np.nan, \"RMSEA\": np.nan,\n",
    "                    \"Simple_Structure_Count\": np.nan, \"Max_Abs_Factor_Corr\": np.nan, \"Error\": str(fit_error)\n",
    "                })\n",
    "\n",
    "\n",
    "    log_message(\"\\n--- Model Comparison Complete ---\")\n",
    "    return pd.DataFrame(summary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70514fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory created/ensured: output\\efa_comparison\\20250506\n",
      "--- Loading Data for Comparison ---\n",
      "Loaded aggregated data: (2250, 102)\n",
      "Identified 97 survey columns based on variable info file.\n",
      "\n",
      "--- Comparing EFA Models (n_factors=5) ---\n",
      "Data Suitability: Bartlett p=0, Overall KMO=0.943\n",
      "Fitting Model: Method='minres', Rotation='promax'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\code\\CultureEval2\\.venv\\lib\\site-packages\\factor_analyzer\\utils.py:244: UserWarning: The inverse of the variance-covariance matrix was calculated using the Moore-Penrose generalized matrix inversion, due to its determinant being at or very close to zero.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Model: Method='minres', Rotation='oblimin'\n",
      "Fitting Model: Method='minres', Rotation='varimax'\n",
      "Fitting Model: Method='principal', Rotation='promax'\n",
      "Fitting Model: Method='principal', Rotation='oblimin'\n",
      "Fitting Model: Method='principal', Rotation='varimax'\n",
      "Fitting Model: Method='ml', Rotation='promax'\n",
      "  Warning: Could not get ML stats for ml+promax: 'FactorAnalyzer' object has no attribute 'get_model_stats'\n",
      "Fitting Model: Method='ml', Rotation='oblimin'\n",
      "  Warning: Could not get ML stats for ml+oblimin: 'FactorAnalyzer' object has no attribute 'get_model_stats'\n",
      "Fitting Model: Method='ml', Rotation='varimax'\n",
      "  Warning: Could not get ML stats for ml+varimax: 'FactorAnalyzer' object has no attribute 'get_model_stats'\n",
      "\n",
      "--- Model Comparison Complete ---\n",
      "\n",
      "==== EFA Comparison Summary (Sorted) ====\n",
      "   Method Rotation  Explained_Var(%)  RMSR  ChiSq_per_DF  RMSEA  Simple_Structure_Count  Max_Abs_Factor_Corr\n",
      "principal   promax            35.224 0.074           NaN    NaN                      58                0.359\n",
      "   minres   promax            31.895 0.077           NaN    NaN                      55                0.419\n",
      "principal  oblimin            35.269 0.082           NaN    NaN                      52                0.397\n",
      "       ml   promax            31.833 0.087           NaN    NaN                      51                0.503\n",
      "   minres  oblimin            31.839 0.090           NaN    NaN                      51                0.502\n",
      "       ml  oblimin            31.852 0.094           NaN    NaN                      50                0.565\n",
      "       ml  varimax            34.847 0.046           NaN    NaN                      48                0.000\n",
      "   minres  varimax            35.250 0.045           NaN    NaN                      46                0.000\n",
      "principal  varimax            38.155 0.047           NaN    NaN                      46                0.000\n",
      "\n",
      "Comparison results saved to: output\\efa_comparison\\20250506\\efa_comparison_summary_n5.csv\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Entry Point\n",
    "# =============================================================================\n",
    "\n",
    "# Define AGGREGATION_DEMOGRAPHIC_VARS globally or pass it if needed for fallback loading\n",
    "AGGREGATION_DEMOGRAPHIC_VARS = [\n",
    "    'B_COUNTRY_ALPHA', 'H_URBRURAL', 'Q260', 'X003R2', 'Q275R',\n",
    "]\n",
    "\n",
    "# I prefer jupyter so commenting out argparse for now\n",
    "if __name__ == \"__main__\":\n",
    "    # parser = argparse.ArgumentParser(description=\"Compare EFA models with different methods and rotations.\")\n",
    "    # parser.add_argument(\"--n_factors\", type=int, default=DEFAULT_N_FACTORS,\n",
    "    #                     help=f\"Number of factors to extract for comparison (default: {DEFAULT_N_FACTORS}).\")\n",
    "    # parser.add_argument(\"--loading_threshold\", type=float, default=DEFAULT_LOADING_THRESHOLD,\n",
    "    #                     help=f\"Absolute loading threshold for simple structure calculation (default: {DEFAULT_LOADING_THRESHOLD:.2f}).\")\n",
    "    # parser.add_argument(\"--agg_file\", default=str(AGGREGATED_DATA_PATH),\n",
    "    #                     help=f\"Path to the input aggregated CSV file (default: {AGGREGATED_DATA_PATH}).\")\n",
    "    # parser.add_argument(\"--var_file\", default=str(VARIABLE_INFO_PATH),\n",
    "    #                     help=f\"Path to the variable info CSV file (default: {VARIABLE_INFO_PATH}).\")\n",
    "    # parser.add_argument(\"--out_dir\", default=str(OUTPUT_DIR_ROOT),\n",
    "    #                      help=f\"Root directory for output (default: {OUTPUT_DIR_ROOT}). A date-stamped subfolder will be created.\")\n",
    "    # parser.add_argument(\"--out_prefix\", default=\"\",\n",
    "    #                      help=\"Optional prefix for the date-stamped output subfolder.\")\n",
    "\n",
    "    # args = parser.parse_args()\n",
    "    # DEFAULT_N_FACTORS\n",
    "    # DEFAULT_LOADING_THRESHOLD\n",
    "    # AGGREGATED_DATA_PATH\n",
    "    # VARIABLE_INFO_PATH\n",
    "    # OUTPUT_DIR_ROOT\n",
    "    \n",
    "\n",
    "    # --- Execute Pipeline ---\n",
    "    try:\n",
    "        # Create specific output directory for this run\n",
    "        output_directory = ensure_output_dir(pathlib.Path(OUTPUT_DIR_ROOT), prefix=\"\")\n",
    "\n",
    "        # Load data\n",
    "        df_efa_input = load_data_for_comparison(\n",
    "            pathlib.Path(AGGREGATED_DATA_PATH), pathlib.Path(VARIABLE_INFO_PATH)\n",
    "        )\n",
    "\n",
    "        # Compare models\n",
    "        comparison_results_df = compare_efa_models(\n",
    "            df_efa_input=df_efa_input,\n",
    "            n_factors=DEFAULT_N_FACTORS,\n",
    "            methods=METHODS_TO_COMPARE,\n",
    "            rotations=ROTATIONS_TO_COMPARE,\n",
    "            simple_structure_threshold=DEFAULT_LOADING_THRESHOLD\n",
    "        )\n",
    "\n",
    "        # Sort results (by minimizing RMSR and maximizing Simple Structure)\n",
    "        df_sorted = comparison_results_df.sort_values(\n",
    "            by=[\"Simple_Structure_Count\", \"RMSR\", \"Explained_Var(%)\"],\n",
    "            ascending=[False, True, False] # High SS count, Low RMSR, High Explained Var\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "        # Print and save summary\n",
    "        log_message(\"\\n==== EFA Comparison Summary (Sorted) ====\")\n",
    "        float_fmt = \"{:.3f}\".format\n",
    "        print(df_sorted.to_string(index=False, float_format=float_fmt, na_rep='NaN'))\n",
    "\n",
    "        summary_csv_path = output_directory / f\"efa_comparison_summary_n{DEFAULT_N_FACTORS}.csv\"\n",
    "        df_sorted.to_csv(summary_csv_path, index=False, float_format='%.4f')\n",
    "        log_message(f\"\\nComparison results saved to: {summary_csv_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"\\nError: Input file not found. {e}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "    except ValueError as e:\n",
    "        print(f\"\\nError: Data validation or configuration issue. {e}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\", file=sys.stderr)\n",
    "        # import traceback\n",
    "        # traceback.print_exc()\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421a34f0",
   "metadata": {},
   "source": [
    "```python\n",
    "Fitting Model: Method='minres', Rotation='oblimin'\n",
    "Fitting Model: Method='minres', Rotation='varimax'\n",
    "Fitting Model: Method='principal', Rotation='promax'\n",
    "Fitting Model: Method='principal', Rotation='oblimin'\n",
    "Fitting Model: Method='principal', Rotation='varimax'\n",
    "Fitting Model: Method='ml', Rotation='promax'\n",
    "  Warning: Could not get ML stats for ml+promax: 'FactorAnalyzer' object has no attribute 'get_model_stats'\n",
    "Fitting Model: Method='ml', Rotation='oblimin'\n",
    "  Warning: Could not get ML stats for ml+oblimin: 'FactorAnalyzer' object has no attribute 'get_model_stats'\n",
    "Fitting Model: Method='ml', Rotation='varimax'\n",
    "  Warning: Could not get ML stats for ml+varimax: 'FactorAnalyzer' object has no attribute 'get_model_stats'\n",
    "\n",
    "--- Model Comparison Complete ---\n",
    "\n",
    "==== EFA Comparison Summary (Sorted) ====\n",
    "   Method Rotation  Explained_Var(%)  RMSR  ChiSq_per_DF  RMSEA  Simple_Structure_Count  Max_Abs_Factor_Corr\n",
    "principal   promax            35.224 0.074           NaN    NaN                      58                0.359\n",
    "   minres   promax            31.895 0.077           NaN    NaN                      55                0.419\n",
    "principal  oblimin            35.269 0.082           NaN    NaN                      52                0.397\n",
    "       ml   promax            31.833 0.087           NaN    NaN                      51                0.503\n",
    "   minres  oblimin            31.839 0.090           NaN    NaN                      51                0.502\n",
    "       ml  oblimin            31.852 0.094           NaN    NaN                      50                0.565\n",
    "       ml  varimax            34.847 0.046           NaN    NaN                      48                0.000\n",
    "   minres  varimax            35.250 0.045           NaN    NaN                      46                0.000\n",
    "principal  varimax            38.155 0.047           NaN    NaN                      46                0.000\n",
    "\n",
    "Comparison results saved to: output\\efa_comparison\\20250506\\efa_comparison_summary_n5.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c569031",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
