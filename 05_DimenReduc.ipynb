{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63479e45",
   "metadata": {},
   "source": [
    "# WVS Wave 7 Data Analysis - Detailed EFA Run\n",
    "\n",
    "This script performs a detailed Exploratory Factor Analysis (EFA) on the aggregated WVS data. It includes suitability tests (Bartlett's, KMO), diagnostic plots (Scree, Parallel Analysis), factor extraction, interpretation of loadings, factor score plotting (optional), and reporting variance explained for a specified EFA model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "07ed7b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Imports\n",
    "# =============================================================================\n",
    "from __future__ import annotations\n",
    "import argparse\n",
    "import datetime as dt\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity, calculate_kmo\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b44dc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Configuration / Constants\n",
    "# =============================================================================\n",
    "DATA_DIR = pathlib.Path(\"./data\")\n",
    "OUTPUT_DIR_ROOT = pathlib.Path(\"./output/efa_detailed\")\n",
    "\n",
    "# --- Input Data ---\n",
    "# AGGREGATED_DATA_PATH = DATA_DIR / \"wvs_wave7_aggregated_by_demographics.csv\"\n",
    "AGGREGATED_DATA_PATH = DATA_DIR / \"new_median_wvs_wave7_aggregated_by_demographics.csv\"\n",
    "# File containing variable codes and question text for interpretation\n",
    "VARIABLE_INFO_PATH = DATA_DIR / \"variable_info.csv\" # Ensure this matches previous scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a935e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Default Parameters ---\n",
    "RANDOM_STATE_DEFAULT = 42\n",
    "DEFAULT_N_FACTORS = 5 # Chosen based on interpretation from comparative analysis\n",
    "DEFAULT_ROTATION = 'promax' # Chosen from comparison\n",
    "DEFAULT_LOADING_THRESHOLD = 0.50 # For interpreting\n",
    "DEFAULT_DEMO_COLOR_COL = 'B_COUNTRY_ALPHA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd32d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Helper Functions\n",
    "# =============================================================================\n",
    "\n",
    "def ensure_output_dir(root: pathlib.Path, prefix: str = \"\") -> pathlib.Path:\n",
    "    \"\"\"Creates a date-stamped output directory.\"\"\"\n",
    "    today = dt.date.today().isoformat().replace(\"-\", \"\")\n",
    "    dir_name = f\"{prefix}{today}\" if prefix else today\n",
    "    out_path = root / dir_name\n",
    "    out_path.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Output directory created/ensured: {out_path}\")\n",
    "    return out_path\n",
    "\n",
    "def create_scree_plot(eigenvalues: np.ndarray, out_path: pathlib.Path) -> None:\n",
    "    \"\"\"Generates and saves a scree plot.\"\"\"\n",
    "    print(\"Generating Scree Plot...\")\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.plot(range(1, len(eigenvalues) + 1), eigenvalues, marker=\"o\", linestyle='-', color='blue')\n",
    "    ax.set_xlabel(\"Component Number\")\n",
    "    ax.set_ylabel(\"Eigenvalue\")\n",
    "    ax.set_title(\"Scree Plot of Eigenvalues\")\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    plt.tight_layout()\n",
    "    try:\n",
    "        filepath = out_path / \"1_scree_plot.png\"\n",
    "        fig.savefig(filepath, dpi=300)\n",
    "        print(f\"Saved Scree Plot to: {filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving Scree Plot: {e}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def run_parallel_analysis(data: pd.DataFrame, n_iter: int = 100, random_state: int = 42) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Performs parallel analysis based on random data generation.\"\"\"\n",
    "    print(f\"Running Parallel Analysis (n_iter={n_iter})...\")\n",
    "    # Calculate observed eigenvalues from data correlation matrix\n",
    "    corr_matrix = data.corr().values\n",
    "    obs_eig, _ = np.linalg.eig(corr_matrix)\n",
    "    obs_eig = np.sort(obs_eig)[::-1] # Sort descending\n",
    "\n",
    "    # Generate random data and calculate eigenvalues\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    n_rows, n_cols = data.shape\n",
    "    rand_eigs_all = np.zeros((n_iter, n_cols))\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        random_data = rng.standard_normal(size=(n_rows, n_cols))\n",
    "        rand_corr = np.corrcoef(random_data, rowvar=False)\n",
    "        rand_eig, _ = np.linalg.eig(rand_corr)\n",
    "        rand_eigs_all[i, :] = np.sort(rand_eig)[::-1]\n",
    "\n",
    "    # Calculate mean of random eigenvalues\n",
    "    rand_eig_mean = rand_eigs_all.mean(axis=0)\n",
    "    print(\"Parallel Analysis complete.\")\n",
    "    return obs_eig, rand_eig_mean\n",
    "\n",
    "def plot_parallel_analysis_results(obs_eig: np.ndarray, rand_eig: np.ndarray, out_path: pathlib.Path) -> None:\n",
    "    \"\"\"Generates and saves a parallel analysis plot.\"\"\"\n",
    "    print(\"Generating Parallel Analysis Plot...\")\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    x_axis = range(1, len(obs_eig) + 1)\n",
    "    ax.plot(x_axis, obs_eig, marker=\"o\", linestyle='-', color='blue', label=\"Observed Eigenvalues\")\n",
    "    ax.plot(x_axis, rand_eig, marker=\"^\", linestyle='--', color='red', label=\"Mean Random Eigenvalues\")\n",
    "    # Add Kaiser criterion line (Eigenvalue = 1)\n",
    "    ax.axhline(1, color='grey', linestyle=':', label='Kaiser Criterion (Eigenvalue=1)')\n",
    "\n",
    "    ax.set_xlabel(\"Component Number\")\n",
    "    ax.set_ylabel(\"Eigenvalue\")\n",
    "    ax.set_title(\"Parallel Analysis\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    plt.tight_layout()\n",
    "    try:\n",
    "        filepath = out_path / \"2_parallel_analysis.png\"\n",
    "        fig.savefig(filepath, dpi=300)\n",
    "        print(f\"Saved Parallel Analysis Plot to: {filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving Parallel Analysis Plot: {e}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def plot_factor_scores(scores: np.ndarray, color_data: pd.Series | None, factor_indices: tuple[int, int], out_path: pathlib.Path) -> None:\n",
    "    \"\"\"Generates and saves a scatter plot of factor scores.\"\"\"\n",
    "    idx1, idx2 = factor_indices\n",
    "    if scores.shape[1] <= max(idx1, idx2):\n",
    "        print(f\"Warning: Not enough factors ({scores.shape[1]}) to plot factors {idx1+1} and {idx2+1}. Skipping score plot.\")\n",
    "        return\n",
    "    if color_data is None:\n",
    "        print(\"Warning: No color data provided. Skipping factor score plot.\")\n",
    "        return\n",
    "    # Ensure color_data length matches scores length\n",
    "    if len(color_data) != scores.shape[0]:\n",
    "         print(f\"Warning: Length mismatch between scores ({scores.shape[0]}) and color data ({len(color_data)}). Skipping score plot.\")\n",
    "         return\n",
    "\n",
    "    print(f\"Generating Factor Score Plot (Factor {idx1+1} vs Factor {idx2+1})...\")\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # pandas factorize to get numerical categories for coloring\n",
    "    color_codes, uniques = pd.factorize(color_data)\n",
    "    scatter = ax.scatter(scores[:, idx1], scores[:, idx2], c=color_codes, s=15, cmap='viridis', alpha=0.7)\n",
    "    ax.set_xlabel(f\"Factor {idx1+1} Score\")\n",
    "    ax.set_ylabel(f\"Factor {idx2+1} Score\")\n",
    "    ax.set_title(\"Factor Score Scatter Plot\")\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Will add a legend if there are a reasonable number of unique categories\n",
    "    if len(uniques) <= 15: # threshold\n",
    "         legend_handles = [plt.Line2D([0], [0], marker='o', color='w', label=label,\n",
    "                                      markerfacecolor=scatter.cmap(scatter.norm(i)), markersize=8)\n",
    "                           for i, label in enumerate(uniques)]\n",
    "         ax.legend(handles=legend_handles, title=color_data.name, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1]) # to make space for legend if outside\n",
    "    try:\n",
    "        filepath = out_path / f\"5_factor_score_scatter_F{idx1+1}_vs_F{idx2+1}.png\"\n",
    "        fig.savefig(filepath, dpi=300)\n",
    "        print(f\"Saved Factor Score Plot to: {filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving Factor Score Plot: {e}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def load_data(aggregated_path: pathlib.Path, variable_info_path: pathlib.Path, demo_color_col: str | None) -> tuple[pd.DataFrame, pd.DataFrame, pd.Series | None, dict]:\n",
    "    \"\"\"Loads aggregated data and variable info, identifies survey columns.\"\"\"\n",
    "    print(\"--- Loading Data ---\")\n",
    "    # Load aggregated data\n",
    "    if not aggregated_path.exists():\n",
    "        raise FileNotFoundError(f\"Aggregated data file not found: {aggregated_path}\")\n",
    "    try:\n",
    "        df_agg = pd.read_csv(aggregated_path)\n",
    "        print(f\"Loaded aggregated data: {df_agg.shape}\")\n",
    "    except Exception as e:\n",
    "        raise IOError(f\"Error reading aggregated data file '{aggregated_path}': {e}\")\n",
    "\n",
    "    # Load variable information for interpretation and column identification\n",
    "    qmap_dict = {}\n",
    "    if variable_info_path.exists():\n",
    "         try:\n",
    "             var_info_df = pd.read_csv(variable_info_path)\n",
    "             print(f\"Loaded variable info: {var_info_df.shape}\")\n",
    "             # Create question text map\n",
    "             qmap_dict = var_info_df.set_index(\"Variable_Code\")[\"Question_Text\"].to_dict()\n",
    "         except Exception as e:\n",
    "             print(f\"Warning: Could not load or process variable info file '{variable_info_path}': {e}\")\n",
    "             var_info_df = pd.DataFrame()\n",
    "    else:\n",
    "        print(f\"Warning: Variable info file not found at '{variable_info_path}'. Question text mapping disabled.\")\n",
    "        var_info_df = pd.DataFrame()\n",
    "\n",
    "    # ---- Note ----\n",
    "    # Identify survey question columns (assume they are all non-demographic columns)\n",
    "    # This requires knowing which columns in df_agg are NOT demographics.\n",
    "    # We infer this by finding columns that ARE in the variable info file.\n",
    "    \n",
    "    if not var_info_df.empty and 'Variable_Code' in var_info_df.columns:\n",
    "         known_vars = var_info_df['Variable_Code'].tolist()\n",
    "         survey_cols = [col for col in df_agg.columns if col in known_vars]\n",
    "         print(f\"Identified {len(survey_cols)} survey columns based on variable info file.\")\n",
    "    else:\n",
    "         # Fallback: assume all numeric columns are survey questions if var_info unavailable\n",
    "         survey_cols = df_agg.select_dtypes(include=np.number).columns.tolist()\n",
    "         print(f\"Warning: Variable info incomplete. Assuming all {len(survey_cols)} numeric columns are survey questions.\")\n",
    "\n",
    "    if not survey_cols:\n",
    "         raise ValueError(\"Could not identify survey question columns for EFA.\")\n",
    "\n",
    "    df_efa_input = df_agg[survey_cols]\n",
    "\n",
    "    # Check for NaNs - aggregated data should ideally be complete\n",
    "    if df_efa_input.isnull().any().any():\n",
    "         print(\"Warning: Missing values found in aggregated data intended for EFA. EFA might fail or produce unreliable results.\")\n",
    "         # Consider adding imputation here IF it's expected, but it usually shouldn't be needed after aggregation.\n",
    "\n",
    "    # Extract color series if requested and available\n",
    "    color_series = None\n",
    "    if demo_color_col:\n",
    "        if demo_color_col in df_agg.columns:\n",
    "            color_series = df_agg[demo_color_col]\n",
    "            print(f\"Using column '{demo_color_col}' for scatter plot coloring.\")\n",
    "        else:\n",
    "            print(f\"Warning: Specified demo color column '{demo_color_col}' not found in aggregated data.\")\n",
    "\n",
    "    return df_agg, df_efa_input, color_series, qmap_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c47e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Main EFA Pipeline Function\n",
    "# =============================================================================\n",
    "\n",
    "def run_efa_analysis(\n",
    "    df_efa_input: pd.DataFrame, # Data for EFA (survey columns only)\n",
    "    df_aggregated: pd.DataFrame, # Full aggregated data (for context/coloring)\n",
    "    color_series: pd.Series | None, # Column for coloring plots\n",
    "    qmap_dict: dict, # Variable_Code -> Question_Text mapping\n",
    "    n_factors: int,\n",
    "    rotation: str,\n",
    "    loading_threshold: float,\n",
    "    out_dir: pathlib.Path\n",
    ") -> None:\n",
    "    \"\"\"Performs the core EFA steps and generates outputs.\"\"\"\n",
    "    print(\"\\n--- Starting EFA Analysis ---\")\n",
    "    print(f\"Parameters: n_factors={n_factors}, rotation='{rotation}', loading_threshold={loading_threshold}\")\n",
    "\n",
    "    # 1. Suitability Tests\n",
    "    print(\"\\n--- 1. Suitability Tests ---\")\n",
    "    try:\n",
    "        chi_square_value, p_value = calculate_bartlett_sphericity(df_efa_input)\n",
    "        print(f\"Bartlett's Test: Chi-Square = {chi_square_value:.3f}, p-value = {p_value:.4g}\")\n",
    "        if p_value > 0.05:\n",
    "             print(\"Warning: Bartlett's test is non-significant (p > 0.05), EFA may not be appropriate.\")\n",
    "\n",
    "        kmo_per_variable, kmo_overall = calculate_kmo(df_efa_input)\n",
    "        print(f\"Kaiser-Meyer-Olkin (KMO) Test: Overall KMO = {kmo_overall:.3f}\")\n",
    "        if kmo_overall < 0.6:\n",
    "             print(\"Warning: Overall KMO < 0.6, indicating data suitability for EFA is questionable.\")\n",
    "        # Save KMO per variable\n",
    "        # pd.Series(kmo_per_variable, index=df_efa_input.columns).to_csv(out_dir / \"kmo_per_variable.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during suitability tests: {e}\")\n",
    "\n",
    "    # 2. Diagnostic Plots (Scree and Parallel Analysis)\n",
    "    print(\"\\n--- 2. Diagnostic Plots ---\")\n",
    "    try:\n",
    "        # Scree Plot (based on initial fit to get eigenvalues)\n",
    "        fa_diag = FactorAnalyzer(n_factors=df_efa_input.shape[1], rotation=None) # Fit all factors for eigenvalues\n",
    "        fa_diag.fit(df_efa_input)\n",
    "        ev, _ = fa_diag.get_eigenvalues()\n",
    "        create_scree_plot(ev, out_dir)\n",
    "\n",
    "        # Parallel Analysis\n",
    "        obs_eig, rand_eig = run_parallel_analysis(df_efa_input, random_state=RANDOM_STATE_DEFAULT)\n",
    "        plot_parallel_analysis_results(obs_eig, rand_eig, out_dir)\n",
    "        \n",
    "        # Determine suggested number of factors from parallel analysis\n",
    "        suggested_n = np.sum(obs_eig > rand_eig)\n",
    "        print(f\"Parallel Analysis suggests retaining {suggested_n} factors (Observed > Random).\")\n",
    "        if suggested_n != n_factors:\n",
    "             print(f\"Note: Suggested factors ({suggested_n}) differs from requested factors ({n_factors}).\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during diagnostic plot generation: {e}\")\n",
    "\n",
    "    # 3. Factor Extraction and Rotation\n",
    "    print(f\"\\n--- 3. Factor Extraction (n_factors={n_factors}, rotation='{rotation}') ---\")\n",
    "    try:\n",
    "        fa = FactorAnalyzer(\n",
    "            n_factors=n_factors,\n",
    "            rotation=rotation,\n",
    "            method=\"principal\", # Others: 'minres', 'ml'\n",
    "            use_smc=True, # Use squared multiple correlation as starting communalities\n",
    "            rotation_kwargs={\"max_iter\": 1000} # For rotations like promax/oblimin\n",
    "        )\n",
    "        fa.fit(df_efa_input)\n",
    "        print(\"Factor analysis fitting complete.\")\n",
    "\n",
    "        # Get Loadings (Pattern Matrix for oblique, Factor Matrix for orthogonal)\n",
    "        loadings = fa.loadings_\n",
    "        pattern_matrix = pd.DataFrame(\n",
    "            loadings,\n",
    "            index=df_efa_input.columns,\n",
    "            columns=[f\"Factor{i+1}\" for i in range(n_factors)],\n",
    "        )\n",
    "        loadings_filename = f\"3_loadings_{rotation}.csv\"\n",
    "        pattern_matrix.to_csv(out_dir / loadings_filename)\n",
    "        print(f\"Saved Factor Loadings to: {out_dir / loadings_filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during factor extraction/rotation: {e}\")\n",
    "        return # Stop if factor extraction fails\n",
    "\n",
    "    # 4. Interpret Strongest Loadings\n",
    "    print(\"\\n--- 4. Interpretation of Strongest Loadings ---\")\n",
    "    print(f\"(Threshold for 'strong' loading: >= {loading_threshold:.2f})\\n\")\n",
    "    interpretation_lines = []\n",
    "    for factor_col in pattern_matrix.columns:\n",
    "        strong_loadings = pattern_matrix[factor_col][pattern_matrix[factor_col].abs() >= loading_threshold]\n",
    "        strong_loadings = strong_loadings.sort_values(key=np.abs, ascending=False)\n",
    "\n",
    "        print(f\"--- {factor_col} ---\")\n",
    "        interpretation_lines.append(f\"--- {factor_col} ---\")\n",
    "        if strong_loadings.empty:\n",
    "            print(\"(No loadings meeting threshold)\")\n",
    "            interpretation_lines.append(\"(No loadings meeting threshold)\")\n",
    "        else:\n",
    "            for var_code, loading in strong_loadings.items():\n",
    "                q_text = qmap_dict.get(var_code, \"(Question text not found)\")\n",
    "                line = f\"  - {loading:.3f} : {q_text} [{var_code}]\"\n",
    "                print(line)\n",
    "                interpretation_lines.append(line)\n",
    "        print(\"-\" * (len(factor_col) + 6))\n",
    "        interpretation_lines.append(\"-\" * (len(factor_col) + 6) + \"\\n\")\n",
    "\n",
    "    # Save interpretation to a text file\n",
    "    try:\n",
    "        interp_path = out_dir / \"4_strongest_loadings_interpretation.txt\"\n",
    "        with open(interp_path, 'w', encoding='utf-8') as f:\n",
    "            f.write('\\n'.join(interpretation_lines))\n",
    "        print(f\"\\nSaved interpretation summary to: {interp_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving interpretation summary: {e}\")\n",
    "\n",
    "\n",
    "    # 5. Factor Scores Plot\n",
    "    print(\"\\n--- 5. Factor Scores Plot ---\")\n",
    "    try:\n",
    "        # Transform data to get factor scores\n",
    "        factor_scores = fa.transform(df_efa_input)\n",
    "        # Plot scores for the first two factors\n",
    "        plot_factor_scores(factor_scores, color_series, (0, 1), out_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating or plotting factor scores: {e}\")\n",
    "\n",
    "\n",
    "    # 6. Variance Explained & Factor Correlations\n",
    "    print(\"\\n--- 6. Variance Explained and Factor Correlations ---\")\n",
    "    try:\n",
    "        variance_info = fa.get_factor_variance() # Returns SSL, Proportion Var, Cumulative Var\n",
    "        variance_df = pd.DataFrame({\n",
    "            \"Factor\": [f\"Factor{i+1}\" for i in range(n_factors)],\n",
    "            \"Sum of Squared Loadings (SSL)\": variance_info[0],\n",
    "            \"Proportion Variance Explained\": variance_info[1],\n",
    "            \"Cumulative Variance Explained\": variance_info[2],\n",
    "        })\n",
    "        var_path = out_dir / \"6_variance_explained.csv\"\n",
    "        variance_df.to_csv(var_path, index=False)\n",
    "        print(f\"Saved Variance Explained to: {var_path}\")\n",
    "        print(\"\\nVariance Summary:\")\n",
    "        print(variance_df.to_string(index=False, float_format=\"{:.3f}\".format))\n",
    "        print(f\"\\nTotal variance explained by {n_factors} factors: {variance_df['Proportion Variance Explained'].sum()*100:.2f}%\")\n",
    "\n",
    "        # Factor Correlation Matrix (Phi) for oblique rotations\n",
    "        if fa.phi_ is not None:\n",
    "            phi_matrix = pd.DataFrame(\n",
    "                fa.phi_,\n",
    "                index=[f\"Factor{i+1}\" for i in range(n_factors)],\n",
    "                columns=[f\"Factor{i+1}\" for i in range(n_factors)]\n",
    "            )\n",
    "            phi_path = out_dir / \"7_factor_correlations_phi.csv\"\n",
    "            phi_matrix.to_csv(phi_path)\n",
    "            print(f\"\\nSaved Factor Correlation Matrix (Phi) to: {phi_path}\")\n",
    "            # print(\"\\nFactor Correlation Matrix (Phi):\")\n",
    "            # print(phi_matrix.to_string(float_format=\"{:.3f}\".format))\n",
    "        else:\n",
    "            print(\"\\nFactor Correlation Matrix (Phi): Not applicable (orthogonal rotation).\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating/saving variance or factor correlations: {e}\")\n",
    "\n",
    "    print(f\"\\n✓ Detailed EFA analysis complete. Results saved in: {out_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53bdfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # =============================================================================\n",
    "# # Entry Point\n",
    "# # =============================================================================\n",
    "\n",
    "# Saving this for future use, if needed.\n",
    "# if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser(description=\"Run a detailed Exploratory Factor Analysis (EFA) on aggregated data.\")\n",
    "#     parser.add_argument(\"--n_factors\", type=int, default=DEFAULT_N_FACTORS,\n",
    "#                         help=f\"Number of factors to extract (default: {DEFAULT_N_FACTORS}). Diagnostics might suggest alternatives.\")\n",
    "#     parser.add_argument(\"--rotation\", choices=[\"promax\", \"oblimin\", \"varimax\", None], default=DEFAULT_ROTATION,\n",
    "#                         help=f\"Rotation method (default: {DEFAULT_ROTATION}). Use None for unrotated solution.\")\n",
    "#     parser.add_argument(\"--loading_threshold\", type=float, default=DEFAULT_LOADING_THRESHOLD,\n",
    "#                         help=f\"Absolute loading threshold for interpretation (default: {DEFAULT_LOADING_THRESHOLD:.2f}).\")\n",
    "#     parser.add_argument(\"--random_state\", type=int, default=RANDOM_STATE_DEFAULT,\n",
    "#                         help=f\"Random state for reproducibility (default: {RANDOM_STATE_DEFAULT}).\")\n",
    "#     parser.add_argument(\"--color_col\", default=DEFAULT_DEMO_COLOR_COL,\n",
    "#                         help=f\"Column name from aggregated data for factor score plot coloring (default: {DEFAULT_DEMO_COLOR_COL}). Set to '' to disable.\")\n",
    "#     parser.add_argument(\"--agg_file\", default=str(AGGREGATED_DATA_PATH),\n",
    "#                         help=f\"Path to the input aggregated CSV file (default: {AGGREGATED_DATA_PATH}).\")\n",
    "#     parser.add_argument(\"--var_file\", default=str(VARIABLE_INFO_PATH),\n",
    "#                         help=f\"Path to the variable info CSV file (default: {VARIABLE_INFO_PATH}).\")\n",
    "#     parser.add_argument(\"--out_dir\", default=str(OUTPUT_DIR_ROOT),\n",
    "#                          help=f\"Root directory for output (default: {OUTPUT_DIR_ROOT}). A date-stamped subfolder will be created.\")\n",
    "#     parser.add_argument(\"--out_prefix\", default=\"01_\",\n",
    "#                          help=\"Optional prefix for the date-stamped output subfolder.\")\n",
    "\n",
    "\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     # Handle potential None rotation from argparse\n",
    "#     rotation_arg = args.rotation if args.rotation != \"None\" else None\n",
    "#     color_col_arg = args.color_col if args.color_col else None # Convert empty string to None\n",
    "\n",
    "#     # --- Execute Pipeline ---\n",
    "#     try:\n",
    "#         # Create specific output directory for this run\n",
    "#         output_directory = ensure_output_dir(pathlib.Path(args.out_dir), prefix=args.out_prefix)\n",
    "\n",
    "#         # Load data\n",
    "#         df_aggregated, df_efa_input, color_series, qmap_dict = load_data(\n",
    "#             pathlib.Path(args.agg_file), pathlib.Path(args.var_file), color_col_arg\n",
    "#         )\n",
    "\n",
    "#         # Run EFA\n",
    "#         run_efa_analysis(\n",
    "#             df_efa_input=df_efa_input,\n",
    "#             df_aggregated=df_aggregated,\n",
    "#             color_series=color_series,\n",
    "#             qmap_dict=qmap_dict,\n",
    "#             n_factors=args.n_factors,\n",
    "#             rotation=rotation_arg,\n",
    "#             loading_threshold=args.loading_threshold,\n",
    "#             out_dir=output_directory\n",
    "#         )\n",
    "\n",
    "#     except FileNotFoundError as e:\n",
    "#         print(f\"\\nError: Input file not found. {e}\", file=sys.stderr)\n",
    "#         sys.exit(1)\n",
    "#     except ValueError as e:\n",
    "#         print(f\"\\nError: Data validation or configuration issue. {e}\", file=sys.stderr)\n",
    "#         sys.exit(1)\n",
    "#     except Exception as e:\n",
    "#         print(f\"\\nAn unexpected error occurred: {e}\", file=sys.stderr)\n",
    "#         # import traceback\n",
    "#         # traceback.print_exc()\n",
    "#         sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7e0f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory created/ensured: output\\efa_detailed\\01_20250506\n",
      "--- Loading Data ---\n",
      "Loaded aggregated data: (2250, 102)\n",
      "Loaded variable info: (227, 4)\n",
      "Identified 97 survey columns based on variable info file.\n",
      "Using column 'B_COUNTRY_ALPHA' for scatter plot coloring.\n",
      "\n",
      "--- Starting EFA Analysis ---\n",
      "Parameters: n_factors=5, rotation='promax', loading_threshold=0.5\n",
      "\n",
      "--- 1. Suitability Tests ---\n",
      "Bartlett's Test: Chi-Square = 119363.633, p-value = 0\n",
      "Kaiser-Meyer-Olkin (KMO) Test: Overall KMO = 0.943\n",
      "\n",
      "--- 2. Diagnostic Plots ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\code\\CultureEval2\\.venv\\lib\\site-packages\\factor_analyzer\\utils.py:244: UserWarning: The inverse of the variance-covariance matrix was calculated using the Moore-Penrose generalized matrix inversion, due to its determinant being at or very close to zero.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Scree Plot...\n",
      "Saved Scree Plot to: output\\efa_detailed\\01_20250506\\1_scree_plot.png\n",
      "Running Parallel Analysis (n_iter=100)...\n",
      "Parallel Analysis complete.\n",
      "Generating Parallel Analysis Plot...\n",
      "Saved Parallel Analysis Plot to: output\\efa_detailed\\01_20250506\\2_parallel_analysis.png\n",
      "Parallel Analysis suggests retaining 16 factors (Observed > Random).\n",
      "Note: Suggested factors (16) differs from requested factors (5).\n",
      "\n",
      "--- 3. Factor Extraction (n_factors=5, rotation='promax') ---\n",
      "Factor analysis fitting complete.\n",
      "Saved Factor Loadings to: output\\efa_detailed\\01_20250506\\3_loadings_promax.csv\n",
      "\n",
      "--- 4. Interpretation of Strongest Loadings ---\n",
      "(Threshold for 'strong' loading: >= 0.50)\n",
      "\n",
      "--- Factor1 ---\n",
      "  - 0.825 : Importance of God [Q164]\n",
      "  - 0.756 : How often to you pray (+) [Q172P]\n",
      "  - 0.734 : Important in life: Religion (+) [Q6P]\n",
      "  - 0.682 : Religious person (+) [Q173P]\n",
      "  - 0.669 : How often do you attend religious services (+) [Q171P]\n",
      "  - -0.658 : Justifiable: Abortion [Q184]\n",
      "  - 0.653 : Believe in: God (+) [Q165P]\n",
      "  - 0.648 : Confidence: Churches (+) [Q64P]\n",
      "  - -0.632 : Justifiable: Euthanasia [Q188]\n",
      "  - 0.567 : How proud of nationality (+) [Q254P]\n",
      "  - -0.544 : Justifiable: Death penalty [Q195]\n",
      "  - 0.522 : Important in life: Work (+) [Q5P]\n",
      "  - 0.507 : One of main goals in life has been to make my parents proud (+) [Q27P]\n",
      "-------------\n",
      "--- Factor2 ---\n",
      "  - 0.833 : Confidence: Parliament (+) [Q73P]\n",
      "  - 0.800 : Confidence: The Political Parties (+) [Q72P]\n",
      "  - 0.754 : Confidence: The Government (+) [Q71P]\n",
      "  - 0.683 : Confidence: The Press (+) [Q66P]\n",
      "  - 0.639 : Confidence: Major Companies (+) [Q77P]\n",
      "  - 0.635 : Confidence: Labor Unions (+) [Q68P]\n",
      "  - 0.534 : Confidence: Justice System/Courts (+) [Q70P]\n",
      "-------------\n",
      "--- Factor3 ---\n",
      "  - 0.726 : Democracy: People choose their leaders in free elections [Q243]\n",
      "  - 0.698 : Democracy: Civil rights protect people’s liberty against oppression [Q246]\n",
      "  - 0.609 : Importance of democracy [Q250]\n",
      "  - 0.561 : Democracy: Women have the same rights as men [Q249]\n",
      "  - -0.531 : Justifiable: Cheating on taxes [Q180]\n",
      "  - 0.523 : Political system: Having a democratic political system (+) [Q238P]\n",
      "  - -0.518 : Competition good or harmful [Q109]\n",
      "-------------\n",
      "--- Factor4 ---\n",
      "  - 0.776 : Jobs scarce: Men should have more right to a job than women (+) [Q33P]\n",
      "  - 0.704 : Men make better political leaders than women do (+) [Q29P]\n",
      "  - 0.682 : The only acceptable religion  is my religion (+) [Q170P]\n",
      "  - 0.672 : Jobs scarce: Employers should give priority to (nation) people than immigrants (+) [Q34P]\n",
      "  - 0.631 : Neighbors: Homosexuals (+) [Q22P]\n",
      "  - 0.625 : Neighbors: Unmarried couples living together (+) [Q25P]\n",
      "  - 0.619 : Duty towards society to have children (+) [Q37P]\n",
      "  - 0.587 : It is child's duty to take care of ill parent (+) [Q38P]\n",
      "  - 0.581 : Whenever science and religion conflict,  religion is always right (+) [Q169P]\n",
      "  - -0.577 : Justifiable: Sex before marriage [Q186]\n",
      "  - -0.561 : Justifiable: Homosexuality [Q182]\n",
      "  - 0.537 : Government has the right: Monitor all e-mails and any other information exchanged on the Internet (+) [Q197P]\n",
      "  - 0.519 : Political system: Having the army rule (+) [Q237P]\n",
      "  - 0.500 : Work should come first even if it means less spare time (+) [Q41P]\n",
      "-------------\n",
      "--- Factor5 ---\n",
      "  - 0.791 : Neighbors: People of a different race (+) [Q19P]\n",
      "  - 0.765 : Neighbors: People who speak a different language (+) [Q26P]\n",
      "  - 0.734 : Neighbors: Immigrants/foreign workers (+) [Q21P]\n",
      "  - 0.631 : Neighbors: People of a different religion (+) [Q23P]\n",
      "-------------\n",
      "\n",
      "Saved interpretation summary to: output\\efa_detailed\\01_20250506\\4_strongest_loadings_interpretation.txt\n",
      "\n",
      "--- 5. Factor Scores Plot ---\n",
      "Generating Factor Score Plot (Factor 1 vs Factor 2)...\n",
      "Saved Factor Score Plot to: output\\efa_detailed\\01_20250506\\5_factor_score_scatter_F1_vs_F2.png\n",
      "\n",
      "--- 6. Variance Explained and Factor Correlations ---\n",
      "Saved Variance Explained to: output\\efa_detailed\\01_20250506\\6_variance_explained.csv\n",
      "\n",
      "Variance Summary:\n",
      " Factor  Sum of Squared Loadings (SSL)  Proportion Variance Explained  Cumulative Variance Explained\n",
      "Factor1                         10.139                          0.105                          0.105\n",
      "Factor2                          6.011                          0.062                          0.166\n",
      "Factor3                          4.916                          0.051                          0.217\n",
      "Factor4                         10.084                          0.104                          0.321\n",
      "Factor5                          3.018                          0.031                          0.352\n",
      "\n",
      "Total variance explained by 5 factors: 35.22%\n",
      "\n",
      "Saved Factor Correlation Matrix (Phi) to: output\\efa_detailed\\01_20250506\\7_factor_correlations_phi.csv\n",
      "\n",
      "✓ Detailed EFA analysis complete. Results saved in: output\\efa_detailed\\01_20250506\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Entry Point\n",
    "# =============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Default configuration values\n",
    "    n_factors = DEFAULT_N_FACTORS\n",
    "    rotation = DEFAULT_ROTATION\n",
    "    loading_threshold = DEFAULT_LOADING_THRESHOLD\n",
    "    random_state = RANDOM_STATE_DEFAULT\n",
    "    color_col = DEFAULT_DEMO_COLOR_COL\n",
    "    agg_file = str(AGGREGATED_DATA_PATH)\n",
    "    var_file = str(VARIABLE_INFO_PATH)\n",
    "    out_dir = str(OUTPUT_DIR_ROOT)\n",
    "    out_prefix = \"01_\"\n",
    "    \n",
    "    # Handle potential None rotation\n",
    "    rotation_arg = rotation if rotation != \"None\" else None\n",
    "    color_col_arg = color_col if color_col else None  # Convert empty string to None\n",
    "    \n",
    "    # --- Execute Pipeline ---\n",
    "    try:\n",
    "        # Create specific output directory for this run\n",
    "        output_directory = ensure_output_dir(pathlib.Path(out_dir), prefix=out_prefix)\n",
    "        \n",
    "        # Load data\n",
    "        df_aggregated, df_efa_input, color_series, qmap_dict = load_data(\n",
    "            pathlib.Path(agg_file), pathlib.Path(var_file), color_col_arg\n",
    "        )\n",
    "        \n",
    "        # Run EFA\n",
    "        run_efa_analysis(\n",
    "            df_efa_input=df_efa_input,\n",
    "            df_aggregated=df_aggregated,\n",
    "            color_series=color_series,\n",
    "            qmap_dict=qmap_dict,\n",
    "            n_factors=n_factors,\n",
    "            rotation=rotation_arg,\n",
    "            loading_threshold=loading_threshold,\n",
    "            out_dir=output_directory\n",
    "        )\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"\\nError: Input file not found. {e}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "    except ValueError as e:\n",
    "        print(f\"\\nError: Data validation or configuration issue. {e}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\", file=sys.stderr)\n",
    "        # import traceback # Uncomment for detailed traceback\n",
    "        sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41212147",
   "metadata": {},
   "source": [
    "```python\n",
    "Generating Scree Plot...\n",
    "Saved Scree Plot to: output\\efa_detailed\\01_20250506\\1_scree_plot.png\n",
    "Running Parallel Analysis (n_iter=100)...\n",
    "Parallel Analysis complete.\n",
    "Generating Parallel Analysis Plot...\n",
    "Saved Parallel Analysis Plot to: output\\efa_detailed\\01_20250506\\2_parallel_analysis.png\n",
    "Parallel Analysis suggests retaining 16 factors (Observed > Random).\n",
    "Note: Suggested factors (16) differs from requested factors (5).\n",
    "\n",
    "--- 3. Factor Extraction (n_factors=5, rotation='promax') ---\n",
    "Factor analysis fitting complete.\n",
    "Saved Factor Loadings to: output\\efa_detailed\\01_20250506\\3_loadings_promax.csv\n",
    "\n",
    "--- 4. Interpretation of Strongest Loadings ---\n",
    "(Threshold for 'strong' loading: >= 0.50)\n",
    "\n",
    "--- Factor1 ---\n",
    "  - 0.825 : Importance of God [Q164]\n",
    "  - 0.756 : How often to you pray (+) [Q172P]\n",
    "  - 0.734 : Important in life: Religion (+) [Q6P]\n",
    "  - 0.682 : Religious person (+) [Q173P]\n",
    "  - 0.669 : How often do you attend religious services (+) [Q171P]\n",
    "  - -0.658 : Justifiable: Abortion [Q184]\n",
    "  - 0.653 : Believe in: God (+) [Q165P]\n",
    "  - 0.648 : Confidence: Churches (+) [Q64P]\n",
    "  - -0.632 : Justifiable: Euthanasia [Q188]\n",
    "  - 0.567 : How proud of nationality (+) [Q254P]\n",
    "  - -0.544 : Justifiable: Death penalty [Q195]\n",
    "  - 0.522 : Important in life: Work (+) [Q5P]\n",
    "  - 0.507 : One of main goals in life has been to make my parents proud (+) [Q27P]\n",
    "-------------\n",
    "--- Factor2 ---\n",
    "  - 0.833 : Confidence: Parliament (+) [Q73P]\n",
    "  - 0.800 : Confidence: The Political Parties (+) [Q72P]\n",
    "  - 0.754 : Confidence: The Government (+) [Q71P]\n",
    "  - 0.683 : Confidence: The Press (+) [Q66P]\n",
    "  - 0.639 : Confidence: Major Companies (+) [Q77P]\n",
    "  - 0.635 : Confidence: Labor Unions (+) [Q68P]\n",
    "  - 0.534 : Confidence: Justice System/Courts (+) [Q70P]\n",
    "-------------\n",
    "--- Factor3 ---\n",
    "  - 0.726 : Democracy: People choose their leaders in free elections [Q243]\n",
    "  - 0.698 : Democracy: Civil rights protect people’s liberty against oppression [Q246]\n",
    "  - 0.609 : Importance of democracy [Q250]\n",
    "  - 0.561 : Democracy: Women have the same rights as men [Q249]\n",
    "  - -0.531 : Justifiable: Cheating on taxes [Q180]\n",
    "  - 0.523 : Political system: Having a democratic political system (+) [Q238P]\n",
    "  - -0.518 : Competition good or harmful [Q109]\n",
    "-------------\n",
    "--- Factor4 ---\n",
    "  - 0.776 : Jobs scarce: Men should have more right to a job than women (+) [Q33P]\n",
    "  - 0.704 : Men make better political leaders than women do (+) [Q29P]\n",
    "  - 0.682 : The only acceptable religion  is my religion (+) [Q170P]\n",
    "  - 0.672 : Jobs scarce: Employers should give priority to (nation) people than immigrants (+) [Q34P]\n",
    "  - 0.631 : Neighbors: Homosexuals (+) [Q22P]\n",
    "  - 0.625 : Neighbors: Unmarried couples living together (+) [Q25P]\n",
    "  - 0.619 : Duty towards society to have children (+) [Q37P]\n",
    "  - 0.587 : It is child's duty to take care of ill parent (+) [Q38P]\n",
    "  - 0.581 : Whenever science and religion conflict,  religion is always right (+) [Q169P]\n",
    "  - -0.577 : Justifiable: Sex before marriage [Q186]\n",
    "  - -0.561 : Justifiable: Homosexuality [Q182]\n",
    "  - 0.537 : Government has the right: Monitor all e-mails and any other information exchanged on the Internet (+) [Q197P]\n",
    "  - 0.519 : Political system: Having the army rule (+) [Q237P]\n",
    "  - 0.500 : Work should come first even if it means less spare time (+) [Q41P]\n",
    "-------------\n",
    "--- Factor5 ---\n",
    "  - 0.791 : Neighbors: People of a different race (+) [Q19P]\n",
    "  - 0.765 : Neighbors: People who speak a different language (+) [Q26P]\n",
    "  - 0.734 : Neighbors: Immigrants/foreign workers (+) [Q21P]\n",
    "  - 0.631 : Neighbors: People of a different religion (+) [Q23P]\n",
    "-------------\n",
    "\n",
    "Saved interpretation summary to: output\\efa_detailed\\01_20250506\\4_strongest_loadings_interpretation.txt\n",
    "\n",
    "--- 5. Factor Scores Plot ---\n",
    "Generating Factor Score Plot (Factor 1 vs Factor 2)...\n",
    "Saved Factor Score Plot to: output\\efa_detailed\\01_20250506\\5_factor_score_scatter_F1_vs_F2.png\n",
    "\n",
    "--- 6. Variance Explained and Factor Correlations ---\n",
    "Saved Variance Explained to: output\\efa_detailed\\01_20250506\\6_variance_explained.csv\n",
    "\n",
    "Variance Summary:\n",
    " Factor  Sum of Squared Loadings (SSL)  Proportion Variance Explained  Cumulative Variance Explained\n",
    "Factor1                         10.139                          0.105                          0.105\n",
    "Factor2                          6.011                          0.062                          0.166\n",
    "Factor3                          4.916                          0.051                          0.217\n",
    "Factor4                         10.084                          0.104                          0.321\n",
    "Factor5                          3.018                          0.031                          0.352\n",
    "\n",
    "Total variance explained by 5 factors: 35.22%\n",
    "\n",
    "Saved Factor Correlation Matrix (Phi) to: output\\efa_detailed\\01_20250506\\7_factor_correlations_phi.csv\n",
    "\n",
    "✓ Detailed EFA analysis complete. Results saved in: output\\efa_detailed\\01_20250506\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10970a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
